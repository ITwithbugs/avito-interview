---

# Интервью (этап: Архитектура AVITO)

Q: Привет. Сегодня будем обсуждать проектирование. Это не про написание кода, а про более высокоуровневое проектирование систем. У тебя есть что-то для рисования? Можно в Miro?
A: Да, давай, открою Miro.

---

Q: Отлично. Мы будем проектировать систему **Classify** — это аналог Avito (объявления). Нужно спроектировать и backend, и frontend, и инфраструктуру, где всё запускать. Расскажу функциональные требования:

1. Поиск объявлений.
2. Просмотр отдельной карточки объявления.
3. Список своих объявлений.
4. Возможность создавать новые объявления.
   У объявлений есть несколько фотографий.

A: Понял. То есть: поиск, просмотр, список своих объявлений, добавление объявлений.

---

Q: Да. Теперь про нагрузку. На старте \~100 RPS, со временем масштабируемся до 20 000 RPS. Нужно проектировать с учётом возможности масштабирования.
A: Окей, будем учитывать рост нагрузки.

Q: Запас по железу сразу на 20 000 RPS, или постепенно масштабируемся?
A: Постепенно. Нужно проектировать систему, которая позволяет горизонтально масштабироваться.

---

Q: По распределению нагрузки: нужен ли гео-распределённый сценарий или достаточно базовой отказоустойчивости?
A: Думаю, для начала хватит базовой отказоустойчивости: несколько стоек/узлов в одном или разных дата-центрах. Минимум 3 мастера в Kubernetes и хотя бы 3 worker-ноды.

Q: Окей, будем считать, что у нас bare-metal, арендуемые дата-центры, не облако.
A: Тогда можно разнести роли по разным серверам. Например:

* Отдельный сервер под Redis (master + replica).
* Отдельные сервера под PostgreSQL (master + реплики через Patroni).
* Отдельное S3-хранилище или аналог для картинок.

---

Q: Хорошо. По поиску — как реализовать полнотекстовый поиск? В PostgreSQL?
A: Да, PostgreSQL поддерживает полнотекстовый поиск. Можно использовать его индексы (GIN/GiST). Но при росте нагрузки стоит подумать про отдельный поисковый движок (например, ElasticSearch).

Q: А Redis / Memcached?
A: Redis можно использовать для кэширования популярных объявлений и списков. Memcached менее удобен для поиска, он больше под key-value.

---

Q: А как хранить фотографии?
A: Лучше вынести в объектное хранилище: S3 или MinIO. В базе хранить только метаданные и ссылки.

---

Q: Хорошо. Что по мониторингу и логированию?
A: Для метрик — Prometheus + Grafana (или VictoriaMetrics + vmagents).
Для логов — ELK (Elasticsearch + Logstash/Fluentd + Kibana).
Сайдкары соберут логи из подов и будут писать в хранилище.

---

Q: Что с CI/CD? Как деплоим код?
A: Используем TeamCity для сборки. Код храним в Bitbucket. Docker-образы складываем в Nexus. Деплой через Helm. На проде можно добавить ArgoCD для GitOps-подхода и observability.

---

Q: Как организуем окружения? Dev/Stage/Prod?
A: В идеале — разные кластера Kubernetes. Но минимальная модель — один кластер и разные namespaces (Dev/Stage/Prod). Для серьёзной компании лучше несколько отдельных кластеров.

---

Q: Хорошо. Что с балансировкой трафика?
A: На входе ставим load balancer (HAProxy или Nginx Ingress). Дальше трафик идёт через Istio (L7-меш), который управляет роутингом, сетевыми политиками и сервис-мешем. Внутри кластера — Calico как CNI для сетей.

---

Q: А авторизация пользователей?
A: Для пользователей — стандартная авторизация (например, JWT). Для разработчиков и админов — RBAC в Kubernetes + SSO (OIDC/SAML).

---

Q: Отлично. Схему в целом описали: балансировка, Kubernetes-кластер, сервисы (поиск, карточка объявления, список, добавление), PostgreSQL с репликами, Redis, S3 для фото, ELK и Prometheus для наблюдаемости, CI/CD через TeamCity + Helm/ArgoCD.
A: Да, именно так.

